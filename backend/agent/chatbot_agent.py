# ì±—ë´‡ ì—ì´ì „íŠ¸ -> ì¼ë°˜ ëŒ€í™”, í• ì¼ ê´€ë¦¬, ë¬¸ì œ ìƒì„±

from agent.todo import TodoToolkit

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from functools import lru_cache

from db import add_todo, view_todos, complete_todo, remove_todo, get_todos_by_user_id
from db import save_chat

import json

# ë¬¸ì œ ìƒì„± ==================================================================



from langchain.agents import Tool
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
import traceback


async def generate_eng_problem(scenario: str) -> str:
    llm = ChatOpenAI(model='gpt-4o', temperature=0)

    print(f"Eng Problem í˜¸ì¶œë¨! ì‹œë‚˜ë¦¬ì˜¤: {scenario}")  # ë¡œê·¸ ì¶”ê°€
    try:
        print(f"ğŸ“¨ ì…ë ¥ëœ ì‹œë‚˜ë¦¬ì˜¤: {scenario}")
        prompt = PromptTemplate(
            input_variables=["scenario"],
            template="""
            ë„ˆëŠ” ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œ ì „ë¬¸ê°€ì•¼. ì£¼ì–´ì§„ ìƒí™©ì€ ì¼ìƒ ìƒí™œì—ì„œ ì¼ì–´ë‚œë‹¤ê³  ê°€ì •í•´.
            ê·¸ ìƒí™©ì— ë§ëŠ” ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œë¥¼ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜. ë¬¸ì œëŠ” ë‹¤ìŒ ê¸°ì¤€ì„ ë”°ë¼ì•¼ í•´:

            - 2025ë…„ í˜„ì¬, ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ì˜ì–´ ìˆ˜ì¤€ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•¨.
            - ê³ ë“±í•™ìƒì´ ê²ªì„ ìˆ˜ ìˆì„ ì¼ìƒ ë“± ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë‹¤ë£° ìˆ˜ ìˆìŒ.
            - ì •ë‹µê³¼ í•´ì„¤ì„ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ. í•´ì„¤ì€ 50ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì¤˜.

            ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì¤˜:
            ë¬¸ì œ: ...  
            ë³´ê¸°:
            A) ...
            B) ...
            C) ...
            D) ...
            ì •ë‹µ: (ì˜ˆ: B)
            í•´ì„¤: (ì´ìœ  ì„¤ëª…)

            ìƒí™©:
            {scenario}

            ì¶œì œëœ ì˜ì–´ ë¬¸ì œ:
            """
        )
        formatted_prompt = prompt.format(scenario=scenario)
        result = await llm.ainvoke(formatted_prompt)
        print("ğŸ“¤ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
        return result.content
    
    except Exception as e:
        error_message = traceback.format_exc()
        print(f"âŒ generate_life_problem ì—ëŸ¬ ë°œìƒ: {e}\n{error_message}")  # ì—ëŸ¬ ë©”ì‹œì§€ ë¡œê·¸
        return "ë¬¸ì œ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."



eng_problem_tool = Tool(
    name="EngProblemTool",
    func=generate_eng_problem,
    coroutine=generate_eng_problem,
    description="ì¼ìƒ ìƒí™œì— ê¸°ë°˜í•´ ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ì •ë‹µê³¼ í•´ì„¤ì„ ì œê³µí•©ë‹ˆë‹¤."
)


@lru_cache()    # íŒŒë¼ë¯¸í„°ê°€ ë™ì¼í•œ í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ë¥¼ ìºì‹œí•´ì„œ ë‘ ë²ˆì§¸ í˜¸ì¶œë¶€í„°ëŠ” ê°™ì€ ê°ì²´ë¥¼ ë°˜í™˜í•´ì¤€ë‹¤. 
def get_agent_executor():
    llm = ChatOpenAI(model='gpt-4o', temperature=0)

# íˆ´ ì¶”ê°€
    todo_toolkit = TodoToolkit()
    todo_tools = todo_toolkit.get_tools()

    tools_for_agent = todo_tools + [eng_problem_tool]

    prompt = ChatPromptTemplate.from_messages([
    ('system', """
        ë„ˆëŠ” ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ë‹¤ìŒ ì„¸ ê°€ì§€ ì—­í• ì„ ìˆ˜í–‰í•´:

        1ï¸âƒ£ **í•  ì¼ ê´€ë¦¬ ìš”ì²­**ì´ ì˜¤ë©´ ì•„ë˜ íˆ´ì„ ì‚¬ìš©í•´ì„œ ì²˜ë¦¬í•´:
        - `add_todo`: "í• ì¼ ì¶”ê°€í•´ì¤˜", "ì˜¤ëŠ˜ ì´ê±° í• ê²Œ", "ë‚´ì¼ ì´ê±° í•  ì˜ˆì •ì´ì•¼" â†’ ìƒˆë¡œìš´ í•  ì¼ì„ ì¶”ê°€í•  ë•Œ
        - `view_todos`: "ì˜¤ëŠ˜ í• ì¼ ë­ì•¼?", "ì¼ì • ë³´ì—¬ì¤˜", "ë‚´ì¼ ì¼ì • ì•Œë ¤ì¤˜" â†’ í•  ì¼ ëª©ë¡ì„ ë³´ì—¬ì¤„ ë•Œ
        - `complete_todo`: "ì´ê±° ë‹¤ í–ˆì–´", "ì™„ë£Œí–ˆì–´", "ëëƒˆì–´", "ì²´í¬í•´ì¤˜" â†’ ì‚¬ìš©ìê°€ íŠ¹ì • í•  ì¼ì„ ëëƒˆì„ ë•Œ 
        - `remove_todo`: "ì´ í• ì¼ ì‚­ì œí•´ì¤˜", "ì§€ì›Œì¤˜", "ì´ ì¼ì • í•„ìš” ì—†ì–´" â†’ íŠ¹ì • í•  ì¼ì„ ì‚­ì œí•´ë‹¬ë¼ê³  í•  ë•Œ
     
        - "ë†€ê³  ì‹¶ì–´", "ì˜¤ëŠ˜ í•  ê±° ê·€ì°®ì•„"ì™€ ê°™ì€ ë¬¸ì¥ì€ ë¨¼ì € view_todos íˆ´ì„ ì‚¬ìš©í•´ ì˜¤ëŠ˜ í•  ì¼ì„ í™•ì¸í•˜ê³ ,
            ê·¸ ê²°ê³¼ì— ë”°ë¼ ì ì ˆíˆ ì‘ë‹µí•´ì•¼ í•´. 

        â†’ ì˜ˆì‹œ:
        {{"action": "add_todo", "title": "ìˆ˜í•™ ë¬¸ì œ í’€ê¸°"}}
        {{"action": "complete_todo", "title": "ìš´ë™í•˜ê¸°"}}
        {{"action": "view_todos"}}

        âš ï¸ `complete_todo` ìš”ì²­ì—ì„œ `view_todos`ë¡œ fallbackí•˜ì§€ ë§ˆ. ëª…í™•íˆ ì™„ë£Œ ìš”ì²­ì´ë©´ `complete_todo` íˆ´ì„ ì‚¬ìš©í•´.

        2ï¸âƒ£ **ì˜ì–´ ë¬¸ì œ ìƒì„± ìš”ì²­**ì´ ì˜¤ë©´ ë°˜ë“œì‹œ `EngProblemTool` íˆ´ì„ ì‚¬ìš©í•´.  
        â†’ ì£¼ì–´ì§„ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œë¥¼ ì¶œì œí•´ì•¼ í•´.

        â†’ ì˜ˆì‹œ:
        {{"action": "EngProblemTool", "title": "ì¹œêµ¬ì™€ ê¸¸ì„ ìƒì€ ìƒí™©"}}

        3ï¸âƒ£ ê·¸ ì™¸ì—ëŠ” **ìì—°ìŠ¤ëŸ½ê²Œ ì¼ìƒ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©´ ë¼**. íˆ´ê³¼ ê´€ë ¨ ì—†ëŠ” ê²½ìš°ì—ëŠ” íˆ´ì„ ì‹¤í–‰í•˜ì§€ ë§ˆ.

        """),
            ('placeholder', '{chat_history}'),
            ('user', '{input}'),
            ('placeholder', '{agent_scratchpad}')
    ])


    agent = create_tool_calling_agent(llm, tools_for_agent, prompt)
    executor = AgentExecutor(
        agent=agent, 
        tools=tools_for_agent, 
        verbose=True, 
        return_intermediate_steps=True
        )

    return executor


from langchain_community.chat_message_histories import ChatMessageHistory
from db import load_chat_history, get_all_user_ids


session_store = {}

def initialize_session_store():
    user_ids = get_all_user_ids()  
    session_ids = user_ids

    for sid in session_ids:
        messages = load_chat_history(sid)  # DBì—ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ ì±„íŒ… ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°
        history = ChatMessageHistory()
        for msg in messages:
            if msg['sender'] == 'user':
                history.add_user_message(msg['message'])
            elif msg['sender'] == 'ai':
                history.add_ai_message(msg['message'])
        session_store[sid] = history




# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ì‹¤í–‰í•˜ëŠ” ë˜í¼ í•¨ìˆ˜
async def invoke_agent(input_text: str, session_id: str, user_id: str):

# âœ… USER Message ì €ì¥
    save_chat(user_id=user_id, sender='user', message=input_text)

    agent_executor = get_agent_executor()

    def get_session_history(sid):
        if sid not in session_store:
            session_store[sid] = ChatMessageHistory()
        return session_store[sid]


    agent_with_history = RunnableWithMessageHistory(
        agent_executor,
        get_session_history,
        input_messages_key='input',
        history_messages_key='chat_history'
    )

    config = {
        'configurable': {
            'session_id': session_id,
        },
    }
    
    # result = agent_with_history.invoke({'input': input_text}, config=config)
    result = await agent_with_history.ainvoke({'input': input_text}, config=config)

    # print(result)
    
# âœ… AI ì‘ë‹µ ì €ì¥
    if result.get("output"):
        save_chat(user_id=user_id, sender='ai', message=result['output'])

# âœ… tools ì‚¬ìš© í™•ì¸ 
    intermediate_steps = result.get('intermediate_steps', [])

    output_message = result['output']

    for step in intermediate_steps:
        action, tool_output = step
        tool_name = action.tool

        if tool_name == "EngProblemTool":
            print("----------------------- EngProblemTool ------------------------------")
            return output_message 

        try:
            parsed = json.loads(tool_output)

        except json.JSONDecodeError:
            continue  # ì˜ëª»ëœ JSONì´ë©´ ë¬´ì‹œ

        if tool_name == "add_todo":
            print("----------------------- add todo ------------------------------")
            title = parsed.get("title")
            if title:
                add_todo(user_id=user_id, title=title)
                todo_output = view_todos(user_id=user_id)
                return f"{output_message}\nğŸ“Œí• ì¼ ëª©ë¡:\n{todo_output}"

        elif tool_name == "view_todos":
            print("----------------------- view todos ------------------------------")
            return f"{output_message}\nğŸ“Œí• ì¼ ëª©ë¡:\n{view_todos(user_id=user_id)}"

        elif tool_name == "complete_todo":
            print("----------------------- complete todo ------------------------------")
            title = parsed.get("title")

            todo_id = await get_todo_id(user_id=user_id, title=title)
            print("todo id => ",{todo_id})

            if todo_id:
                complete_todo(user_id=user_id, todo_id=todo_id)
                todo_output = view_todos(user_id=user_id)
                return f"ğŸ‰ {output_message}\nğŸ“Œí• ì¼ ëª©ë¡:\n{todo_output}"
            else:
                return "âŒ í•´ë‹¹ í•  ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
            

        elif tool_name == "remove_todo":
            print("----------------------- remove todo ------------------------------")
            title = parsed.get("title")
            todo_id = await get_todo_id(user_id=user_id, title=title)
            print("todo id => ",{todo_id})

            if todo_id:
                remove_todo(user_id=user_id, todo_id=todo_id)
                todo_output = view_todos(user_id=user_id)
                return f"ğŸ—‘ï¸ {output_message}\nğŸ“Œí• ì¼ ëª©ë¡:\n{todo_output}"
            else:
                return "âŒ í•´ë‹¹ í•  ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
    
    print("----------------------- ì¼ë°˜ ì±„íŒ… ------------------------------")
    return output_message


async def get_todo_id(user_id, title) -> str:
    todos = get_todos_by_user_id(user_id=user_id)

    todo_json = json.dumps(todos, ensure_ascii=False, indent=2)


    llm_prompt = f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ í•  ì¼ ëª©ë¡ì…ë‹ˆë‹¤.

        {todo_json}

        ì‚¬ìš©ìì˜ í• ì¼: "{title}"

        ìœ„ ëª©ë¡ ì¤‘ ì–´ë–¤ í•­ëª©ì— í•´ë‹¹í•˜ëŠ” ê²ƒì¸ì§€ ì¶”ë¡ í•˜ì—¬, ê°€ì¥ ì ì ˆí•œ todoì˜ IDë¥¼ ìˆ«ì í•˜ë‚˜ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

        í˜•ì‹: ìˆ«ì(ID)ë§Œ ë‹¨ë…ìœ¼ë¡œ ì¶œë ¥
    """

    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    todo_id_result = await llm.ainvoke(llm_prompt)

    todo_id = todo_id_result.content.strip()
    
    return todo_id
