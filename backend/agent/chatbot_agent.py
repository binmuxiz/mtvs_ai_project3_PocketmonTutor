# ì±—ë´‡ ì—ì´ì „íŠ¸ -> ì¼ë°˜ ëŒ€í™”, í• ì¼ ê´€ë¦¬, ë¬¸ì œ ìƒì„±

from agent.todo import TodoToolkit

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from functools import lru_cache

from db import add_todo, view_todos, complete_todo, remove_todo, get_todos_by_user_id
from db import save_chat

import json

# ë¬¸ì œ ìƒì„± ==================================================================



from langchain.agents import Tool
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
import traceback


async def generate_eng_problem(scenario: str) -> str:
    llm = ChatOpenAI(model='gpt-4o', temperature=0)

    print(f"Eng Problem í˜¸ì¶œë¨! ì‹œë‚˜ë¦¬ì˜¤: {scenario}")  # ë¡œê·¸ ì¶”ê°€
    try:
        print(f"ğŸ“¨ ì…ë ¥ëœ ì‹œë‚˜ë¦¬ì˜¤: {scenario}")
        prompt = PromptTemplate(
            input_variables=["scenario"],
            template="""
            ë„ˆëŠ” ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œ ì „ë¬¸ê°€ì•¼. ì£¼ì–´ì§„ ìƒí™©ì€ ì¼ìƒ ìƒí™œì—ì„œ ì¼ì–´ë‚œë‹¤ê³  ê°€ì •í•´.
            ê·¸ ìƒí™©ì— ë§ëŠ” ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œë¥¼ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜. ë¬¸ì œëŠ” ë‹¤ìŒ ê¸°ì¤€ì„ ë”°ë¼ì•¼ í•´:

            - 2025ë…„ í˜„ì¬, ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ì˜ì–´ ìˆ˜ì¤€ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•¨.
            - ê³ ë“±í•™ìƒì´ ê²ªì„ ìˆ˜ ìˆì„ ì¼ìƒ ë“± ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë‹¤ë£° ìˆ˜ ìˆìŒ.
            - ì •ë‹µê³¼ í•´ì„¤ì„ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ. í•´ì„¤ì€ 50ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì¤˜.

            ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì¤˜:
            ë¬¸ì œ: ...
            ë³´ê¸°:
            A) ...
            B) ...
            C) ...
            D) ...
            ì •ë‹µ: (ì˜ˆ: B)
            í•´ì„¤: (ì´ìœ  ì„¤ëª…)

            ìƒí™©:
            {scenario}

            ì¶œì œëœ ì˜ì–´ ë¬¸ì œ:
            """
        )
        formatted_prompt = prompt.format(scenario=scenario)
        result = await llm.ainvoke(formatted_prompt)
        print("ğŸ“¤ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
        return result.content
    
    except Exception as e:
        error_message = traceback.format_exc()
        print(f"âŒ generate_life_problem ì—ëŸ¬ ë°œìƒ: {e}\n{error_message}")  # ì—ëŸ¬ ë©”ì‹œì§€ ë¡œê·¸
        return "ë¬¸ì œ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."



eng_problem_tool = Tool(
    name="EngProblemTool",
    func=generate_eng_problem,
    coroutine=generate_eng_problem,
    description="ì¼ìƒ ìƒí™œì— ê¸°ë°˜í•´ ê³ ë“±í•™êµ ì˜ì–´ ë‚´ì‹  ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ì •ë‹µê³¼ í•´ì„¤ì„ ì œê³µí•©ë‹ˆë‹¤."
)


@lru_cache()    # íŒŒë¼ë¯¸í„°ê°€ ë™ì¼í•œ í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ë¥¼ ìºì‹œí•´ì„œ ë‘ ë²ˆì§¸ í˜¸ì¶œë¶€í„°ëŠ” ê°™ì€ ê°ì²´ë¥¼ ë°˜í™˜í•´ì¤€ë‹¤. 
def get_agent_executor():
    llm = ChatOpenAI(model='gpt-4o', temperature=0)

# íˆ´ ì¶”ê°€
    todo_toolkit = TodoToolkit()
    todo_tools = todo_toolkit.get_tools()

    tools_for_agent = todo_tools + [eng_problem_tool]

    prompt = ChatPromptTemplate.from_messages([
        ('system', """
        ë„ˆëŠ” ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
                
        ë„ˆì˜ ì—­í• ì€ ë‹¤ìŒê³¼ ê°™ì•„:
                
        1. ì‚¬ìš©ìì˜ í•  ì¼ ê´€ë¦¬ ìš”ì²­ì´ ì˜¤ë©´, íˆ´ì„ ì‚¬ìš©í•´ì„œ ì²˜ë¦¬í•´. (add/view/complete/remove)
        2. ì˜ì–´ ë¬¸ì œ ìƒì„±ì„ ìš”ì²­ë°›ìœ¼ë©´, ë°˜ë“œì‹œ "EngProblemTool" íˆ´ì„ ì‚¬ìš©í•´ ë¬¸ì œë¥¼ ìƒì„±í•´.
        3. ê·¸ ì™¸ ì¼ìƒ ëŒ€í™”ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´.
        
         **ì¤‘ìš”**:
         - íˆ´ì„ ì‚¬ìš©í•  ë• JSONìœ¼ë¡œ ëª…í™•í•˜ê²Œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•´. ì˜ˆ: 
         {{"action": "add_todo", "title": "ìˆ˜í•™ 10ë¬¸ì œ í’€ê¸°"}}
         {{"action": "EngProblemTool", "title": "ì¹œêµ¬ì™€ ê¸¸ì„ ìƒì€ ìƒí™©"}}
         - íˆ´ ì‚¬ìš©ì´ ì•„ë‹Œ ê²½ìš°ì—” ìì—°ìŠ¤ëŸ½ê²Œ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•˜ë©´ ë¼.
         - ì‚¬ìš©ìê°€ ëª…í™•íˆ íˆ´ê³¼ ê´€ë ¨ëœ ìš”ì²­ì„ í•˜ì§€ ì•Šìœ¼ë©´, íˆ´ì„ ì‹¤í–‰í•˜ì§€ ë§ˆ.

         ì˜ˆì‹œ:
        - "ì˜¤ëŠ˜ ë­í• ê¹Œ?" â†’ ìì—°ì–´ ì‘ë‹µ
        - "í•  ì¼ ëª©ë¡ ë³´ì—¬ì¤˜" â†’ {{"action": "view_todos"}}
        - "ì˜¤ëŠ˜ í• ê±° ë•Œë ¤ì¹˜ê³  ë…¸ë˜ë°©ì´ë‚˜ ê°ˆë¼" â†’ {{"action": "view_todos"}}
            - ì´ëŸ° ê²½ìš°ì—” ì˜¤ëŠ˜ì˜ í• ì¼ ëª©ë¡ì„ í™•ì¸í•˜ê³  ì ì ˆí•œ ëŒ€ë‹µ ìƒì„±. ì˜ˆ: "ì˜¤ëŠ˜ ì•„ë˜ì™€ ê°™ì€ í• ì¼ë“¤ì´ ì¡´ì¬í•´ìš”. ë…¸ë˜ë°©ì€ í• ì¼ì„ ë‹¤ í•˜ê³  ê°‘ì‹œë‹¤!"
         

        """),
        ('placeholder', '{chat_history}'),
        ('user', '{input}'),
        ('placeholder', '{agent_scratchpad}')
    ])

    agent = create_tool_calling_agent(llm, tools_for_agent, prompt)
    executor = AgentExecutor(
        agent=agent, 
        tools=tools_for_agent, 
        verbose=True, 
        return_intermediate_steps=True
        )

    return executor


from langchain_community.chat_message_histories import ChatMessageHistory
from db import load_chat_history, get_all_user_ids


session_store = {}

def initialize_session_store():
    user_ids = get_all_user_ids()  
    session_ids = user_ids

    for sid in session_ids:
        messages = load_chat_history(sid)  # DBì—ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ ì±„íŒ… ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°
        history = ChatMessageHistory()
        for msg in messages:
            if msg['sender'] == 'user':
                history.add_user_message(msg['message'])
            elif msg['sender'] == 'ai':
                history.add_ai_message(msg['message'])
        session_store[sid] = history




# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ì‹¤í–‰í•˜ëŠ” ë˜í¼ í•¨ìˆ˜
async def invoke_agent(input_text: str, session_id: str, user_id: str):

# âœ… USER Message ì €ì¥
    save_chat(user_id=user_id, sender='user', message=input_text)

    agent_executor = get_agent_executor()

    def get_session_history(sid):
        if sid not in session_store:
            session_store[sid] = ChatMessageHistory()
        return session_store[sid]


    agent_with_history = RunnableWithMessageHistory(
        agent_executor,
        get_session_history,
        input_messages_key='input',
        history_messages_key='chat_history'
    )

    config = {
        'configurable': {
            'session_id': session_id,
        },
    }
    
    # result = agent_with_history.invoke({'input': input_text}, config=config)
    result = await agent_with_history.ainvoke({'input': input_text}, config=config)

    # print(result)
    
# âœ… AI ì‘ë‹µ ì €ì¥
    if result.get("output"):
        save_chat(user_id=user_id, sender='ai', message=result['output'])

# âœ… tools ì‚¬ìš© í™•ì¸ 
    intermediate_steps = result.get('intermediate_steps', [])

    output_message = result['output']

    for step in intermediate_steps:
        action, tool_output = step
        tool_name = action.tool

        if tool_name == "EngProblemTool":
            print("----------------------- EngProblemTool ------------------------------")
            return tool_output 

        try:
            parsed = json.loads(tool_output)
        except json.JSONDecodeError:
            continue  # ì˜ëª»ëœ JSONì´ë©´ ë¬´ì‹œ

        if tool_name == "add_todo":
            print("----------------------- add todo ------------------------------")
            title = parsed.get("title")
            if title:
                add_todo(user_id=user_id, title=title)
                return output_message

        elif tool_name == "view_todos":
            print("----------------------- view todos ------------------------------")
            return view_todos(user_id=user_id)

        elif tool_name == "complete_todo":
            print("----------------------- complete todo ------------------------------")
            title = parsed.get("title")
            todo_id = parsed.get("todo_id")
            print("1. todo id => ",{todo_id})

            todo_id = await get_todo_id(user_id=user_id, title=title)
            print("2. todo id => ",{todo_id})

            if todo_id:
                complete_todo(user_id=user_id, todo_id=todo_id)
                return f"ğŸ‰ {output_message}"
            else:
                return "âŒ í•´ë‹¹ í•  ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
            

        elif tool_name == "remove_todo":
            print("----------------------- remove todo ------------------------------")
            title = parsed.get("title")
            todo_id = parsed.get("todo_id")
            print("1. todo id => ",{todo_id})

            todo_id = await get_todo_id(user_id=user_id, title=title)
            print("2. todo id => ",{todo_id})

            if todo_id:
                remove_todo(user_id=user_id, todo_id=todo_id)
                return f"ğŸ—‘ï¸ {output_message}"
            else:
                return "âŒ í•´ë‹¹ í•  ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”."
    
    print("----------------------- ì¼ë°˜ ì±„íŒ… ------------------------------")
    return output_message


async def get_todo_id(user_id, title) -> str:
    todos = get_todos_by_user_id(user_id=user_id)

    todo_json = json.dumps(todos, ensure_ascii=False, indent=2)


    llm_prompt = f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ í•  ì¼ ëª©ë¡ì…ë‹ˆë‹¤.

        {todo_json}

        ì‚¬ìš©ìì˜ í• ì¼: "{title}"

        ìœ„ ëª©ë¡ ì¤‘ ì–´ë–¤ í•­ëª©ì— í•´ë‹¹í•˜ëŠ” ê²ƒì¸ì§€ ì¶”ë¡ í•˜ì—¬, ê°€ì¥ ì ì ˆí•œ todoì˜ IDë¥¼ ìˆ«ì í•˜ë‚˜ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

        í˜•ì‹: ìˆ«ì(ID)ë§Œ ë‹¨ë…ìœ¼ë¡œ ì¶œë ¥
    """

    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    todo_id_result = await llm.ainvoke(llm_prompt)

    todo_id = todo_id_result.content.strip()
    
    return todo_id
